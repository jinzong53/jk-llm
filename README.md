
<h1 align="center">ğŸš€ JK-LLMï¼šä»é›¶æ„å»ºç®€æ˜“å¤§è¯­è¨€æ¨¡å‹</h1>

<!-- <p align="center">
[English Version](README_en.md) | [ä¸­æ–‡ç‰ˆæœ¬](README.md)
</p> -->

<p align="center">
ä½¿ç”¨ PyTorch å®ç° Decoder-Only Transformerï¼ˆGPT-likeï¼‰æ¨¡å‹ï¼Œä»é›¶å¼€å§‹ç†è§£ LLM çš„å†…éƒ¨ç»“æ„ä¸è®­ç»ƒè¿‡ç¨‹
</p>

<p align="center">
<a><img src="https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?logo=pytorch&logoColor=white"></a>
<a><img src="https://img.shields.io/badge/Python-3.8+-3776AB?logo=python&logoColor=white"></a>
<a><img src="https://img.shields.io/badge/License-MIT-green.svg"></a>
<a><img src="https://img.shields.io/badge/Model-GPT%20from%20scratch-blue"></a>
</p>

---

## ğŸ“– ç›®å½•

* [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
* [åŠŸèƒ½ç‰¹ç‚¹](#åŠŸèƒ½ç‰¹ç‚¹)
* [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
* [å®‰è£…å’Œç¯å¢ƒé…ç½®](#å®‰è£…å’Œç¯å¢ƒé…ç½®)
* [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
* [æ¨¡å‹æ¶æ„](#æ¨¡å‹æ¶æ„)
* [è®­ç»ƒä¸æ¨ç†](#è®­ç»ƒä¸æ¨ç†)
* [å®éªŒæŒ‡æ ‡](#å®éªŒæŒ‡æ ‡)
* [æœªæ¥è®¡åˆ’](#æœªæ¥è®¡åˆ’)

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

**JK-LLM** æ˜¯ä¸€ä¸ª**ç®€æ˜“å‘**çš„ LLM ä»£ç ä»“åº“ï¼Œæ—¨åœ¨å¸®åŠ©ä½ ï¼š

* ç†è§£æœ€åŸºç¡€çš„ LLM çš„å·¥ä½œåŸç†
* æŒæ¡ Transformer Decoder ç»“æ„
* å­¦ä¼šè®­ç»ƒã€è¯„ä¼°å’Œæ¨ç†æµç¨‹
* æ¨¡æ‹Ÿ GPT-like æ¨¡å‹å¯¹è¯


---

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹

| åŠŸèƒ½æ¨¡å—         | å†…å®¹                                            |
| ------------ | --------------------------------------------- |
| ğŸ”¥ æ¨¡å‹        | Decoder-Only Transformer (GPT-style)          |
| ğŸ§  Tokenizer | SentencePiece BPE                             |
| ğŸ“¦ æ•°æ®        | æ»‘åŠ¨çª—å£æ–‡æœ¬è®­ç»ƒé›†æ„å»º                                   |
| âš™ï¸ è®­ç»ƒ        | AdamW + AMP + Grad Accum + Warmup + Cosine LR |
| ğŸ“Š è¯„ä¼°        | Cross entropy & perplexity                    |
| âœï¸ æ¨ç†        | Greedy decoding æ–‡æœ¬ç”Ÿæˆ                          |

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
jk-llm/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/          # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ models/        # Transformerå®ç°
â”‚   â”œâ”€â”€ tokenizer/     # SentencePiece tokenizer
â”‚   â”œâ”€â”€ train.py       # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ evaluate.py    # éªŒè¯/å›°æƒ‘åº¦
â”‚   â””â”€â”€ infer.py       # æ–‡æœ¬ç”Ÿæˆæ¨ç†
â”œâ”€â”€ configs/           # YAMLé…ç½®
â”œâ”€â”€ artifacts/         # è¯­æ–™ & ç”Ÿæˆæ–‡ä»¶(.gitignore)
â””â”€â”€ checkpoints/       # æ¨¡å‹æƒé‡(.gitignore)
```

---

## ğŸ› ï¸ å®‰è£…å’Œç¯å¢ƒé…ç½®

### âœ… ç¯å¢ƒè¦æ±‚

* Python â‰¥ 3.8
* PyTorch â‰¥ 2.0
* GPUï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰

### âš™ï¸ å®‰è£…æ­¥éª¤

**Step 1ï¼šå®‰è£… PyTorchï¼ˆæ ¹æ®ç³»ç»Ÿï¼‰**

> æ¨èä½¿ç”¨å®˜ç½‘å‘½ä»¤ï¼š[https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)

ä¾‹å¦‚ï¼ˆCPUï¼‰ï¼š

```bash
pip install --upgrade pip
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

ä¾‹å¦‚ï¼ˆCUDA 11.8ï¼‰ï¼š

```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

**Step 2ï¼šå®‰è£…å…¶ä»–ä¾èµ–**

```bash
pip install -r requirements.txt
```

---

## ğŸ“š æ•°æ®å‡†å¤‡

### 0ï¸âƒ£ ä¸‹è½½æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰

ä½ å¯ä»¥ä» [ç™¾åº¦AI Studio](https://aistudio.baidu.com/datasetdetail/83697) ä¸‹è½½æ–°é—»æ•°æ®é›†ã€‚ä¸‹è½½åï¼Œæ•°æ®é›†ä¸º.datæ ¼å¼ï¼Œä½ éœ€è¦å°†å…¶è½¬æ¢ä¸º.txtæ ¼å¼å¹¶æ”¾å…¥ `artifacts/corpus/` ç›®å½•ä¸‹çš„ `train.txt`ã€`val.txt` å’Œ `test.txt` æ–‡ä»¶ä¸­ã€‚

### 1ï¸âƒ£ å‡†å¤‡åŸå§‹è¯­æ–™ï¼ˆè‡ªè¡Œæ”¾å…¥ï¼‰

```
artifacts/corpus/train.txt
artifacts/corpus/val.txt
artifacts/corpus/test.txt
```

### 2ï¸âƒ£ è®­ç»ƒåˆ†è¯å™¨

```bash
python src/tokenizer/train_tokenizer.py
```

### 3ï¸âƒ£ æ„å»ºè®­ç»ƒæ•°æ®é›†

```bash
python src/data/build_datasets.py
```

---

## ğŸ§  æ¨¡å‹æ¶æ„

> Decoder-Only Transformerï¼ˆç±» GPTï¼‰

æ ¸å¿ƒç½‘ç»œï¼š

```python
class DecoderOnlyTransformer(nn.Module):
    ...
```

åŒ…å«ï¼š

* Token + Position Embedding
* å¤šå¤´è‡ªæ³¨æ„åŠ› + å› æœ Mask
* FFN + GELU
* LayerNorm + æ®‹å·®
* äº¤å‰ç†µè®­ç»ƒç›®æ ‡

---

## ğŸš€ è®­ç»ƒä¸æ¨ç†

### ğŸ‹ï¸ å¯åŠ¨è®­ç»ƒ

```bash
python src/train.py --config configs/train_small.yaml
```

### âœ… è¯„ä¼°å›°æƒ‘åº¦

```bash
python src/evaluate.py
```

### âœ¨ æ–‡æœ¬ç”Ÿæˆ

```bash
python src/infer.py --prompt "Hello world"
```

---

## ğŸ“ˆ å®éªŒæŒ‡æ ‡

| æŒ‡æ ‡         | è¯´æ˜            |
| ---------- | ------------- |
| Loss       | Cross entropy |
| Perplexity | exp(loss)     |
| Speed      | tokens/sec    |
| Memory     | GPU æ˜¾å­˜å ç”¨      |

---

## ğŸ”­ æœªæ¥è®¡åˆ’

* [ ] åŠ å…¥ Flash-Attention
* [ ] åŠ å…¥ RoPE / ALiBi ä½ç½®ç¼–ç 
* [ ] åŠ å…¥ RLHF / LoRA finetune demo
* [ ] æä¾›ä¸­æ–‡è®­ç»ƒæ ·ä¾‹
* [ ] å‘å¸ƒ Colab Notebook

---


æœ¬é¡¹ç›®ä½¿ç”¨ **MIT License**ã€‚
